{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import random\n",
    "import copy\n",
    "\n",
    "random.seed(a=0)\n",
    "\n",
    "class GeneticPool(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        populationSize = 40, \n",
    "        mutationRate = 0.1, \n",
    "        ins = None,\n",
    "        outs = None):\n",
    "\n",
    "        self.populationSize = populationSize\n",
    "        self.mutationRate = mutationRate\n",
    "        self.poolLR = [0.1, 0.5]\n",
    "        self.poolInputNeurons = [4,8,12,16]\n",
    "        self.poolHiddenLayer = [1,0.5,1.5,2]\n",
    "        \n",
    "    def generatePopulation(self):\n",
    "        self.chromosomes = []\n",
    "        for _ in range(self.populationSize):\n",
    "            self.chromosomes.append(self.generateChromosome())\n",
    "           \n",
    "                      \n",
    "    def generateChromosome(self):\n",
    "        class Chromosome:\n",
    "            LR = random.uniform(self.poolLR[0], self.poolLR[1])\n",
    "            InputNeurons = self.poolInputNeurons[random.randint(1,len(self.poolInputNeurons))-1]          \n",
    "            HiddenLayer = self.poolHiddenLayer[random.randint(1,len(self.poolHiddenLayer))-1]\n",
    "            Error = 0\n",
    "            pesoEnt = []\n",
    "            pesoSal = []\n",
    "        chromosome = Chromosome() \n",
    "        return chromosome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Entry point to evolving the neural network. Start here.\"\"\"\n",
    "import logging\n",
    "from optimizer import Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_networks(networks, dataset):\n",
    "    \"\"\"Train each network.\n",
    "\n",
    "    Args:\n",
    "        networks (list): Current population of networks\n",
    "        dataset (str): Dataset to use for training/evaluating\n",
    "    \"\"\"\n",
    "    pbar = tqdm(total=len(networks))\n",
    "    for network in networks:\n",
    "        network.train(dataset)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "def get_average_accuracy(networks):\n",
    "    \"\"\"Get the average accuracy for a group of networks.\n",
    "\n",
    "    Args:\n",
    "        networks (list): List of networks\n",
    "\n",
    "    Returns:\n",
    "        float: The average accuracy of a population of networks.\n",
    "\n",
    "    \"\"\"\n",
    "    total_accuracy = 0\n",
    "    for network in networks:\n",
    "        total_accuracy += network.accuracy\n",
    "\n",
    "    return total_accuracy / len(networks)\n",
    "\n",
    "def generate(generations, population, nn_param_choices, dataset):\n",
    "    \"\"\"Generate a network with the genetic algorithm.\n",
    "\n",
    "    Args:\n",
    "        generations (int): Number of times to evole the population\n",
    "        population (int): Number of networks in each generation\n",
    "        nn_param_choices (dict): Parameter choices for networks\n",
    "        dataset (str): Dataset to use for training/evaluating\n",
    "\n",
    "    \"\"\"\n",
    "    optimizer = Optimizer(nn_param_choices)\n",
    "    networks = optimizer.create_population(population)\n",
    "\n",
    "    # Evolve the generation.\n",
    "    for i in range(generations):\n",
    "        logging.info(\"***Doing generation %d of %d***\" %\n",
    "                     (i + 1, generations))\n",
    "\n",
    "        # Train and get accuracy for networks.\n",
    "        train_networks(networks, dataset)\n",
    "\n",
    "        # Get the average accuracy for this generation.\n",
    "        average_accuracy = get_average_accuracy(networks)\n",
    "\n",
    "        # Print out the average accuracy each generation.\n",
    "        logging.info(\"Generation average: %.2f%%\" % (average_accuracy * 100))\n",
    "        logging.info('-'*80)\n",
    "\n",
    "        # Evolve, except on the last iteration.\n",
    "        if (i != generations - 1):\n",
    "            # Do the evolution.\n",
    "            networks = optimizer.evolve(networks)\n",
    "\n",
    "    # Sort our final population.\n",
    "    networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n",
    "\n",
    "    # Print out the top 5 networks.\n",
    "    print_networks(networks[:5])\n",
    "\n",
    "def print_networks(networks):\n",
    "    \"\"\"Print a list of networks.\n",
    "\n",
    "    Args:\n",
    "        networks (list): The population of networks\n",
    "\n",
    "    \"\"\"\n",
    "    logging.info('-'*80)\n",
    "    for network in networks:\n",
    "        network.print_network()\n",
    "\n",
    "def main():\n",
    "    generations = 10  # Number of times to evole the population.\n",
    "    population = 20  # Number of networks in each generation.\n",
    "\n",
    "    nn_param_choices = {\n",
    "        'nb_neurons': [4,6,8,10,12,16,20],\n",
    "        'i_neurons': [4,8,12,16],\n",
    "        'nb_layers': [1, 2, 3, 4],\n",
    "        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n",
    "        'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n",
    "                      'adadelta', 'adamax', 'nadam'],\n",
    "    }\n",
    "\n",
    "    logging.info(\"***Evolving %d generations with population %d***\" %\n",
    "                 (generations, population))\n",
    "\n",
    "    generate(generations, population, nn_param_choices, dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class that holds a genetic algorithm for evolving a network.\n",
    "\n",
    "Credit:\n",
    "    A lot of those code was originally inspired by:\n",
    "    http://lethain.com/genetic-algorithms-cool-name-damn-simple/\n",
    "\"\"\"\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import random\n",
    "from network import Network\n",
    "\n",
    "class Optimizer():\n",
    "    \"\"\"Class that implements genetic algorithm for MLP optimization.\"\"\"\n",
    "\n",
    "    def __init__(self, nn_param_choices, retain=0.4,\n",
    "                 random_select=0.1, mutate_chance=0.2):\n",
    "        \"\"\"Create an optimizer.\n",
    "\n",
    "        Args:\n",
    "            nn_param_choices (dict): Possible network paremters\n",
    "            retain (float): Percentage of population to retain after\n",
    "                each generation\n",
    "            random_select (float): Probability of a rejected network\n",
    "                remaining in the population\n",
    "            mutate_chance (float): Probability a network will be\n",
    "                randomly mutated\n",
    "\n",
    "        \"\"\"\n",
    "        self.mutate_chance = mutate_chance\n",
    "        self.random_select = random_select\n",
    "        self.retain = retain\n",
    "        self.nn_param_choices = nn_param_choices\n",
    "\n",
    "    def create_population(self, count):\n",
    "        \"\"\"Create a population of random networks.\n",
    "\n",
    "        Args:\n",
    "            count (int): Number of networks to generate, aka the\n",
    "                size of the population\n",
    "\n",
    "        Returns:\n",
    "            (list): Population of network objects\n",
    "\n",
    "        \"\"\"\n",
    "        pop = []\n",
    "        for _ in range(0, count):\n",
    "            # Create a random network.\n",
    "            network = Network(self.nn_param_choices)\n",
    "            network.create_random()\n",
    "\n",
    "            # Add the network to our population.\n",
    "            pop.append(network)\n",
    "\n",
    "        return pop\n",
    "\n",
    "    @staticmethod\n",
    "    def fitness(network):\n",
    "        \"\"\"Return the accuracy, which is our fitness function.\"\"\"\n",
    "        return network.accuracy\n",
    "\n",
    "    def grade(self, pop):\n",
    "        \"\"\"Find average fitness for a population.\n",
    "\n",
    "        Args:\n",
    "            pop (list): The population of networks\n",
    "\n",
    "        Returns:\n",
    "            (float): The average accuracy of the population\n",
    "\n",
    "        \"\"\"\n",
    "        summed = reduce(add, (self.fitness(network) for network in pop))\n",
    "        return summed / float((len(pop)))\n",
    "\n",
    "    def breed(self, mother, father):\n",
    "        \"\"\"Make two children as parts of their parents.\n",
    "\n",
    "        Args:\n",
    "            mother (dict): Network parameters\n",
    "            father (dict): Network parameters\n",
    "\n",
    "        Returns:\n",
    "            (list): Two network objects\n",
    "\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        for _ in range(2):\n",
    "\n",
    "            child = {}\n",
    "\n",
    "            # Loop through the parameters and pick params for the kid.\n",
    "            for param in self.nn_param_choices:\n",
    "                child[param] = random.choice(\n",
    "                    [mother.network[param], father.network[param]]\n",
    "                )\n",
    "\n",
    "            # Now create a network object.\n",
    "            network = Network(self.nn_param_choices)\n",
    "            network.create_set(child)\n",
    "\n",
    "            # Randomly mutate some of the children.\n",
    "            if self.mutate_chance > random.random():\n",
    "                network = self.mutate(network)\n",
    "\n",
    "            children.append(network)\n",
    "\n",
    "        return children\n",
    "\n",
    "    def mutate(self, network):\n",
    "        \"\"\"Randomly mutate one part of the network.\n",
    "\n",
    "        Args:\n",
    "            network (dict): The network parameters to mutate\n",
    "\n",
    "        Returns:\n",
    "            (Network): A randomly mutated network object\n",
    "\n",
    "        \"\"\"\n",
    "        # Choose a random key.\n",
    "        mutation = random.choice(list(self.nn_param_choices.keys()))\n",
    "\n",
    "        # Mutate one of the params.\n",
    "        network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n",
    "\n",
    "        return network\n",
    "\n",
    "    def evolve(self, pop):\n",
    "        \"\"\"Evolve a population of networks.\n",
    "\n",
    "        Args:\n",
    "            pop (list): A list of network parameters\n",
    "\n",
    "        Returns:\n",
    "            (list): The evolved population of networks\n",
    "\n",
    "        \"\"\"\n",
    "        # Get scores for each network.\n",
    "        graded = [(self.fitness(network), network) for network in pop]\n",
    "\n",
    "        # Sort on the scores.\n",
    "        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n",
    "\n",
    "        # Get the number we want to keep for the next gen.\n",
    "        retain_length = int(len(graded)*self.retain)\n",
    "\n",
    "        # The parents are every network we want to keep.\n",
    "        parents = graded[:retain_length]\n",
    "\n",
    "        # For those we aren't keeping, randomly keep some anyway.\n",
    "        for individual in graded[retain_length:]:\n",
    "            if self.random_select > random.random():\n",
    "                parents.append(individual)\n",
    "\n",
    "        # Now find out how many spots we have left to fill.\n",
    "        parents_length = len(parents)\n",
    "        desired_length = len(pop) - parents_length\n",
    "        children = []\n",
    "\n",
    "        # Add children, which are bred from two remaining networks.\n",
    "        while len(children) < desired_length:\n",
    "\n",
    "            # Get a random mom and dad.\n",
    "            male = random.randint(0, parents_length-1)\n",
    "            female = random.randint(0, parents_length-1)\n",
    "\n",
    "            # Assuming they aren't the same network...\n",
    "            if male != female:\n",
    "                male = parents[male]\n",
    "                female = parents[female]\n",
    "\n",
    "                # Breed them.\n",
    "                babies = self.breed(male, female)\n",
    "\n",
    "                # Add the children one at a time.\n",
    "                for baby in babies:\n",
    "                    # Don't grow larger than desired length.\n",
    "                    if len(children) < desired_length:\n",
    "                        children.append(baby)\n",
    "\n",
    "        parents.extend(children)\n",
    "\n",
    "        return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Class that represents the network to be evolved.\"\"\"\n",
    "import random\n",
    "import logging\n",
    "from train import train_and_score\n",
    "\n",
    "class Network():\n",
    "    \"\"\"Represent a network and let us operate on it.\n",
    "\n",
    "    Currently only works for an MLP.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nn_param_choices=None):\n",
    "        \"\"\"Initialize our network.\n",
    "\n",
    "        Args:\n",
    "            nn_param_choices (dict): Parameters for the network, includes:\n",
    "                nb_neurons (list): [64, 128, 256]\n",
    "                nb_layers (list): [1, 2, 3, 4]\n",
    "                activation (list): ['relu', 'elu']\n",
    "                optimizer (list): ['rmsprop', 'adam']\n",
    "        \"\"\"\n",
    "        self.accuracy = 0.\n",
    "        self.nn_param_choices = nn_param_choices\n",
    "        self.network = {}  # (dic): represents MLP network parameters\n",
    "\n",
    "    def create_random(self):\n",
    "        \"\"\"Create a random network.\"\"\"\n",
    "        for key in self.nn_param_choices:\n",
    "            self.network[key] = random.choice(self.nn_param_choices[key])\n",
    "\n",
    "    def create_set(self, network):\n",
    "        \"\"\"Set network properties.\n",
    "\n",
    "        Args:\n",
    "            network (dict): The network parameters\n",
    "\n",
    "        \"\"\"\n",
    "        self.network = network\n",
    "\n",
    "    def train(self, dataset):\n",
    "        \"\"\"Train the network and record the accuracy.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Name of dataset to use.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.accuracy == 0.:\n",
    "            self.accuracy = train_and_score(self.network, dataset)\n",
    "\n",
    "    def print_network(self):\n",
    "        \"\"\"Print out a network.\"\"\"\n",
    "        logging.info(self.network)\n",
    "        logging.info(\"Network accuracy: %.2f%%\" % (self.accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility used by the Network class to actually train.\n",
    "\n",
    "Based on:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py\n",
    "\n",
    "\"\"\"\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Helper: Early stopping.\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "\n",
    "def get_cifar10():\n",
    "    \"\"\"Retrieve the CIFAR dataset and process the data.\"\"\"\n",
    "    # Set defaults.\n",
    "    nb_classes = 10\n",
    "    batch_size = 64\n",
    "    input_shape = (3072,)\n",
    "\n",
    "    # Get the data.\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.reshape(50000, 3072)\n",
    "    x_test = x_test.reshape(10000, 3072)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = to_categorical(y_train, nb_classes)\n",
    "    y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n",
    "\n",
    "def get_mnist():\n",
    "    \"\"\"Retrieve the MNIST dataset and process the data.\"\"\"\n",
    "    # Set defaults.\n",
    "    nb_classes = 10\n",
    "    batch_size = 128\n",
    "    input_shape = (784,)\n",
    "\n",
    "    # Get the data.\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = to_categorical(y_train, nb_classes)\n",
    "    y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n",
    "\n",
    "def compile_model(network, nb_classes, input_shape):\n",
    "    \"\"\"Compile a sequential model.\n",
    "\n",
    "    Args:\n",
    "        network (dict): the parameters of the network\n",
    "\n",
    "    Returns:\n",
    "        a compiled network.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get our network parameters.\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    i_neurons = network['i_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add each layer.\n",
    "    for i in range(nb_layers):\n",
    "\n",
    "        # Need input shape for first layer.\n",
    "        if i == 0:\n",
    "            model.add(Dense(i_neurons, activation=activation, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Dense(nb_neurons, activation=activation))\n",
    "\n",
    "        model.add(Dropout(0.2))  # hard-coded dropout\n",
    "\n",
    "    # Output layer.\n",
    "    model.add(Dense(nb_classes, activation=activation))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_and_score(network, dataset):\n",
    "    \"\"\"Train the model, return test loss.\n",
    "\n",
    "    Args:\n",
    "        network (dict): the parameters of the network\n",
    "        dataset (str): Dataset to use for training/evaluating\n",
    "\n",
    "    \"\"\"\n",
    "    if dataset == 'cifar10':\n",
    "        nb_classes, batch_size, input_shape, x_train, \\\n",
    "            x_test, y_train, y_test = get_cifar10()\n",
    "    elif dataset == 'mnist':\n",
    "        nb_classes, batch_size, input_shape, x_train, \\\n",
    "            x_test, y_train, y_test = get_mnist()\n",
    "\n",
    "    model = compile_model(network, nb_classes, input_shape)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10000,  # using early stopping, so no real limit\n",
    "              verbose=0,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stopper])\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    return score[1]  # 1 is accuracy. 0 is loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 1254s 7us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\"\"\"Retrieve the CIFAR dataset and process the data.\"\"\"\n",
    "# Set defaults.\n",
    "serie1 = TimeSeriesNN3(1,14,Serie_1,6)\n",
    "nb_classes = 1\n",
    "batch_size = 1\n",
    "input_shape = (6,)\n",
    "\n",
    "# Get the data.\n",
    "(x_train, y_train), (x_test, y_test) = serie1.batch()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# convert class vectors to binary class matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesNN3():\n",
    "    def __init__(self,STEPS_AHEAD ,NUMBER_TESTING , SERIE, WINDOW):\n",
    "        self.STEPS_AHEAD = STEPS_AHEAD\n",
    "        self.WINDOW = WINDOW\n",
    "        self.NUMBER_TESTING = NUMBER_TESTING\n",
    "        self.SERIE = SERIE\n",
    "        self.SIZE = SERIE.shape[0]\n",
    "        self.NUMBER_TRAINING = self.SIZE - self.NUMBER_TESTING\n",
    "    \n",
    "    def divide_testing (self):\n",
    "        return (self.SERIE[:self.NUMBER_TRAINING],self.SERIE[self.NUMBER_TRAINING:])\n",
    "    \n",
    "    def divide_validation (self,serie):\n",
    "        experimentx = np.zeros((len(serie) - self.WINDOW -self.STEPS_AHEAD + 1, self.WINDOW))\n",
    "        experimenty = np.zeros((len(serie) - self.WINDOW -self.STEPS_AHEAD + 1,1))\n",
    "        cnt =  0\n",
    "        cnt2 = 0\n",
    "        serie = serie.reset_index(drop = True)\n",
    "        for i in range (experimentx.shape[0]):\n",
    "            cnt += cnt2\n",
    "            for j in range (self.WINDOW):\n",
    "                experimentx[i][j] = serie[cnt]\n",
    "                cnt += 1   \n",
    "            experimenty[i] = serie[cnt + self.STEPS_AHEAD - 1]\n",
    "            cnt = 0\n",
    "            cnt2 += 1           \n",
    "        return (experimentx, experimenty)\n",
    "    \n",
    "    def batch (self):\n",
    "        training,testing = self.divide_testing()\n",
    "        tex,tey = self.divide_validation(testing)\n",
    "        tx,ty = self.divide_validation(training)        \n",
    "        return (tx,ty) , (tex,tey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import random\n",
    "import copy\n",
    "\n",
    "training_data = pd.read_excel(\"NN3_FINAL_DATASET_WITH_TEST_DATA.xlsx\",sheet_name=\"Hoja 1\")\n",
    "Serie_1 = training_data[\"Serie 5\"]\n",
    "MINIMO = np.amin(Serie_1)\n",
    "Serie_1 = (abs(MINIMO)+ Serie_1)\n",
    "MAXIMO = np.amax(Serie_1)\n",
    "Serie_1 = Serie_1 / MAXIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 15 12\n",
      "Train on 118 samples, validate on 2 samples\n",
      "Epoch 1/10000\n",
      "118/118 [==============================] - 2s 19ms/step - loss: 0.0622 - mean_squared_error: 0.0622 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
      "Epoch 2/10000\n",
      "118/118 [==============================] - 0s 449us/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 3/10000\n",
      "118/118 [==============================] - 0s 416us/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
      "Epoch 4/10000\n",
      "118/118 [==============================] - 0s 492us/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 5/10000\n",
      "118/118 [==============================] - 0s 339us/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 6/10000\n",
      "118/118 [==============================] - 0s 390us/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 7/10000\n",
      "118/118 [==============================] - 0s 314us/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 8/10000\n",
      "118/118 [==============================] - 0s 416us/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 8.7891e-04 - val_mean_squared_error: 8.7891e-04\n",
      "Epoch 9/10000\n",
      "118/118 [==============================] - 0s 339us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 5.6603e-04 - val_mean_squared_error: 5.6603e-04\n",
      "Epoch 10/10000\n",
      "118/118 [==============================] - 0s 322us/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 3.3113e-04 - val_mean_squared_error: 3.3113e-04\n",
      "Epoch 11/10000\n",
      "118/118 [==============================] - 0s 305us/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 2.5007e-04 - val_mean_squared_error: 2.5007e-04\n",
      "Epoch 12/10000\n",
      "118/118 [==============================] - 0s 314us/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 2.3515e-04 - val_mean_squared_error: 2.3515e-04\n",
      "Epoch 13/10000\n",
      "118/118 [==============================] - 0s 339us/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 2.1763e-04 - val_mean_squared_error: 2.1763e-04\n",
      "Epoch 14/10000\n",
      "118/118 [==============================] - 0s 331us/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 1.6540e-04 - val_mean_squared_error: 1.6540e-04\n",
      "Epoch 15/10000\n",
      "118/118 [==============================] - 0s 339us/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 1.5595e-04 - val_mean_squared_error: 1.5595e-04\n",
      "Epoch 16/10000\n",
      "118/118 [==============================] - 0s 373us/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 1.6021e-04 - val_mean_squared_error: 1.6021e-04\n",
      "Epoch 17/10000\n",
      "118/118 [==============================] - 0s 373us/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 1.0053e-04 - val_mean_squared_error: 1.0053e-04\n",
      "Epoch 18/10000\n",
      "118/118 [==============================] - 0s 407us/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 7.8170e-05 - val_mean_squared_error: 7.8170e-05\n",
      "Epoch 19/10000\n",
      "118/118 [==============================] - 0s 407us/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 6.5140e-05 - val_mean_squared_error: 6.5140e-05\n",
      "Epoch 20/10000\n",
      "118/118 [==============================] - 0s 399us/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 5.1963e-05 - val_mean_squared_error: 5.1963e-05\n",
      "Epoch 21/10000\n",
      "118/118 [==============================] - 0s 407us/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 8.9081e-05 - val_mean_squared_error: 8.9081e-05\n",
      "Epoch 22/10000\n",
      "118/118 [==============================] - 0s 382us/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 9.3796e-05 - val_mean_squared_error: 9.3796e-05\n",
      "Epoch 23/10000\n",
      "118/118 [==============================] - 0s 373us/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 1.4321e-04 - val_mean_squared_error: 1.4321e-04\n",
      "Epoch 24/10000\n",
      "118/118 [==============================] - 0s 433us/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 1.3904e-04 - val_mean_squared_error: 1.3904e-04\n",
      "Epoch 25/10000\n",
      "118/118 [==============================] - 0s 424us/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 1.4308e-04 - val_mean_squared_error: 1.4308e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopper = EarlyStopping(patience=5)\n",
    "def compile_model(network, nb_classes, input_shape):\n",
    "    \"\"\"Compile a sequential model.\n",
    "\n",
    "    Args:\n",
    "        network (dict): the parameters of the network\n",
    "\n",
    "    Returns:\n",
    "        a compiled network.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get our network parameters.\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    i_neurons = network['i_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "    print(nb_layers,nb_neurons,i_neurons)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add each layer.\n",
    "    for i in range(nb_layers):\n",
    "\n",
    "        # Need input shape for first layer.\n",
    "        if i == 0:\n",
    "            model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Dense(nb_neurons, activation=activation))\n",
    "\n",
    "        model.add(Dropout(0.2))  # hard-coded dropout\n",
    "\n",
    "    # Output layer.\n",
    "    model.add(Dense(nb_classes, activation=activation))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mean_squared_error'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\"\"\"Retrieve the CIFAR dataset and process the data.\"\"\"\n",
    "# Set defaults.\n",
    "serie1 = TimeSeriesNN3(1,14,Serie_1,12)\n",
    "nb_classes = 1\n",
    "batch_size = 4\n",
    "input_shape = (12,)\n",
    "\n",
    "# Get the data.\n",
    "(x_train, y_train), (x_test, y_test) = serie1.batch()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "\n",
    "network = {\n",
    "        'nb_neurons': 15,\n",
    "        'i_neurons': 12,\n",
    "        'nb_layers': 1,\n",
    "        'activation': 'sigmoid',\n",
    "        'optimizer':  'adam'\n",
    "    }\n",
    "\n",
    "model = compile_model(network, 1, input_shape)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10000,  # using early stopping, so no real limit\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[early_stopper])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "p2 = model.predict(x_train)\n",
    "plt.plot(p2)\n",
    "plt.plot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_7_input to have 3 dimensions, but got array with shape (124, 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-766554bfdd80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m           callbacks=[early_stopper])\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_7_input to have 3 dimensions, but got array with shape (124, 6)"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Retrieve the CIFAR dataset and process the data.\"\"\"\n",
    "# Set defaults.\n",
    "serie1 = TimeSeriesNN3(1,14,Serie_1,6)\n",
    "nb_classes = 1\n",
    "batch_size = 1\n",
    "input_shape = (1,1)\n",
    "\n",
    "# Get the data.\n",
    "(x_train, y_train), (x_test, y_test) = serie1.batch()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "\n",
    "network = {\n",
    "        'nb_neurons': 600,\n",
    "        'i_neurons': 12,\n",
    "        'nb_layers': 4,\n",
    "        'activation': 'sigmoid',\n",
    "        'optimizer':  'adam'\n",
    "    }\n",
    "\n",
    "model = compile_model(network, 1, (6,))\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10000,  # using early stopping, so no real limit\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[early_stopper])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(patience=20)\n",
    "def compile_model(network, nb_classes, input_shape):\n",
    "    \"\"\"Compile a sequential model.\n",
    "\n",
    "    Args:\n",
    "        network (dict): the parameters of the network\n",
    "\n",
    "    Returns:\n",
    "        a compiled network.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get our network parameters.\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    i_neurons = network['i_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(12, 1)))  \n",
    "    model.add(Dropout(0.2))  \n",
    "    model.add(LSTM(units=50, return_sequences=True))  \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units=50, return_sequences=True))  \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units=50))  \n",
    "    model.add(Dropout(0.2))  \n",
    "    model.add(Dense(units = 1))  \n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')  \n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set defaults.\n",
    "nb_classes = 10\n",
    "batch_size = 64\n",
    "input_shape = (3072,)\n",
    "\n",
    "# Get the data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.reshape(50000, 3072)\n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, nb_classes)\n",
    "y_test = to_categorical(y_test, nb_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [9]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
