{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import random\n",
    "import copy\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import Functions\n",
    "\n",
    "# Setup logging.\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='FFNN.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "nb_classes = 0\n",
    "test_size = 0\n",
    "serie = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    \"\"\"Class that implements genetic algorithm for MLP optimization.\"\"\"\n",
    "\n",
    "    def __init__(self, nn_param_choices, retain=0.4,\n",
    "                 random_select=0.1, mutate_chance=0.2):\n",
    "        \"\"\"Create an optimizer.\n",
    "\n",
    "        Args:\n",
    "            nn_param_choices (dict): Possible network paremters\n",
    "            retain (float): Percentage of population to retain after\n",
    "                each generation\n",
    "            random_select (float): Probability of a rejected network\n",
    "                remaining in the population\n",
    "            mutate_chance (float): Probability a network will be\n",
    "                randomly mutated\n",
    "\n",
    "        \"\"\"\n",
    "        self.mutate_chance = mutate_chance\n",
    "        self.random_select = random_select\n",
    "        self.retain = retain\n",
    "        self.nn_param_choices = nn_param_choices\n",
    "\n",
    "    def create_population(self, count):\n",
    "        \"\"\"Create a population of random networks.\n",
    "\n",
    "        Args:\n",
    "            count (int): Number of networks to generate, aka the\n",
    "                size of the population\n",
    "\n",
    "        Returns:\n",
    "            (list): Population of network objects\n",
    "\n",
    "        \"\"\"\n",
    "        pop = []\n",
    "        for _ in range(0, count):\n",
    "            # Create a random network.\n",
    "            network = Network(self.nn_param_choices)\n",
    "            network.create_random()\n",
    "\n",
    "            # Add the network to our population.\n",
    "            pop.append(network)\n",
    "\n",
    "        return pop\n",
    "\n",
    "    @staticmethod\n",
    "    def fitness(network):\n",
    "        \"\"\"Return the accuracy, which is our fitness function.\"\"\"\n",
    "        return network.accuracy\n",
    "\n",
    "    def grade(self, pop):\n",
    "        \"\"\"Find average fitness for a population.\n",
    "\n",
    "        Args:\n",
    "            pop (list): The population of networks\n",
    "\n",
    "        Returns:\n",
    "            (float): The average accuracy of the population\n",
    "\n",
    "        \"\"\"\n",
    "        summed = reduce(add, (self.fitness(network) for network in pop))\n",
    "        return summed / float((len(pop)))\n",
    "\n",
    "    def breed(self, mother, father):\n",
    "        \"\"\"Make two children as parts of their parents.\n",
    "\n",
    "        Args:\n",
    "            mother (dict): Network parameters\n",
    "            father (dict): Network parameters\n",
    "\n",
    "        Returns:\n",
    "            (list): Two network objects\n",
    "\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        for _ in range(2):\n",
    "\n",
    "            child = {}\n",
    "\n",
    "            # Loop through the parameters and pick params for the kid.\n",
    "            for param in self.nn_param_choices:\n",
    "                child[param] = random.choice(\n",
    "                    [mother.network[param], father.network[param]]\n",
    "                )\n",
    "\n",
    "            # Now create a network object.\n",
    "            network = Network(self.nn_param_choices)\n",
    "            network.create_set(child)\n",
    "\n",
    "            # Randomly mutate some of the children.\n",
    "            if self.mutate_chance > random.random():\n",
    "                network = self.mutate(network)\n",
    "\n",
    "            children.append(network)\n",
    "\n",
    "        return children\n",
    "\n",
    "    def mutate(self, network):\n",
    "        \"\"\"Randomly mutate one part of the network.\n",
    "\n",
    "        Args:\n",
    "            network (dict): The network parameters to mutate\n",
    "\n",
    "        Returns:\n",
    "            (Network): A randomly mutated network object\n",
    "\n",
    "        \"\"\"\n",
    "        # Choose a random key.\n",
    "        mutation = random.choice(list(self.nn_param_choices.keys()))\n",
    "\n",
    "        # Mutate one of the params.\n",
    "        network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n",
    "\n",
    "        return network\n",
    "\n",
    "    def evolve(self, pop):\n",
    "        \"\"\"Evolve a population of networks.\n",
    "\n",
    "        Args:\n",
    "            pop (list): A list of network parameters\n",
    "\n",
    "        Returns:\n",
    "            (list): The evolved population of networks\n",
    "\n",
    "        \"\"\"\n",
    "        # Get scores for each network.\n",
    "        graded = [(self.fitness(network), network) for network in pop]\n",
    "\n",
    "        # Sort on the scores.\n",
    "        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n",
    "\n",
    "        # Get the number we want to keep for the next gen.\n",
    "        retain_length = int(len(graded)*self.retain)\n",
    "\n",
    "        # The parents are every network we want to keep.\n",
    "        parents = graded[:retain_length]\n",
    "\n",
    "        # For those we aren't keeping, randomly keep some anyway.\n",
    "        for individual in graded[retain_length:]:\n",
    "            if self.random_select > random.random():\n",
    "                parents.append(individual)\n",
    "\n",
    "        # Now find out how many spots we have left to fill.\n",
    "        parents_length = len(parents)\n",
    "        desired_length = len(pop) - parents_length\n",
    "        children = []\n",
    "\n",
    "        # Add children, which are bred from two remaining networks.\n",
    "        while len(children) < desired_length:\n",
    "\n",
    "            # Get a random mom and dad.\n",
    "            male = random.randint(0, parents_length-1)\n",
    "            female = random.randint(0, parents_length-1)\n",
    "\n",
    "            # Assuming they aren't the same network...\n",
    "            if male != female:\n",
    "                male = parents[male]\n",
    "                female = parents[female]\n",
    "\n",
    "                # Breed them.\n",
    "                babies = self.breed(male, female)\n",
    "\n",
    "                # Add the children one at a time.\n",
    "                for baby in babies:\n",
    "                    # Don't grow larger than desired length.\n",
    "                    if len(children) < desired_length:\n",
    "                        children.append(baby)\n",
    "\n",
    "        parents.extend(children)\n",
    "\n",
    "        return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    \"\"\"Represent a network and let us operate on it.\n",
    "\n",
    "    Currently only works for an MLP.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nn_param_choices=None):\n",
    "        \"\"\"Initialize our network.\n",
    "\n",
    "        Args:\n",
    "            nn_param_choices (dict): Parameters for the network, includes:\n",
    "                nb_neurons (list): [64, 128, 256]\n",
    "                nb_layers (list): [1, 2, 3, 4]\n",
    "                activation (list): ['relu', 'elu']\n",
    "                optimizer (list): ['rmsprop', 'adam']\n",
    "        \"\"\"\n",
    "        self.accuracy = 0.\n",
    "        self.nn_param_choices = nn_param_choices\n",
    "        self.network = {}  # (dic): represents MLP network parameters\n",
    "\n",
    "    def create_random(self):\n",
    "        \"\"\"Create a random network.\"\"\"\n",
    "        for key in self.nn_param_choices:\n",
    "            self.network[key] = random.choice(self.nn_param_choices[key])\n",
    "\n",
    "    def create_set(self, network):\n",
    "        \"\"\"Set network properties.\n",
    "\n",
    "        Args:\n",
    "            network (dict): The network parameters\n",
    "\n",
    "        \"\"\"\n",
    "        self.network = network\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the network and record the accuracy.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Name of dataset to use.\n",
    "\n",
    "        \"\"\"\n",
    "        #if self.accuracy == 0.:\n",
    "        mse = train_and_score(self.network)\n",
    "        self.accuracy = 1/ mse\n",
    "        self.mse =  mse\n",
    "\n",
    "    def print_network(self):\n",
    "        \"\"\"Print out a network.\"\"\"\n",
    "        logging.info(self.network)\n",
    "        logging.info(\"Network MSE: %.10f%%\" % (1/self.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(network):\n",
    "    global nb_classes\n",
    "    \"\"\"Compile a sequential model.\n",
    "\n",
    "    Args:\n",
    "        network (dict): the parameters of the network\n",
    "\n",
    "    Returns:\n",
    "        a compiled network.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get our network parameters.\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    i_neurons = network['i_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "\n",
    "    model = Sequential()\n",
    "    input_shape = (i_neurons, )\n",
    "    \n",
    "  \n",
    "\n",
    "    # Add each layer.\n",
    "    for i in range(nb_layers):\n",
    "\n",
    "        # Need input shape for first layer.\n",
    "        if i == 0:\n",
    "            model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Dense(nb_neurons, activation=activation))\n",
    "\n",
    "        model.add(Dropout(0.2))  # hard-coded dropout\n",
    "\n",
    "    # Output layer.\n",
    "    model.add(Dense(nb_classes, activation=activation))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mean_squared_error'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_and_score(network):\n",
    "\n",
    "    batch_size = 1\n",
    "    i_neurons = network['i_neurons']\n",
    "    # Set defaults.\n",
    "    serie1 = Functions.TimeSeriesNN3(nb_classes,test_size,serie,i_neurons)\n",
    "\n",
    "    # Get the data.\n",
    "    (x_train, y_train), (x_test, y_test) = serie1.batch()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    model = compile_model(network)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10000,  # using early stopping, so no real limit\n",
    "              verbose=0,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stopper])\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(score)\n",
    "\n",
    "    return score[1]  # 1 is accuracy. 0 is loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_networks(networks):\n",
    "    \"\"\"Train each network.\n",
    "\n",
    "    Args:\n",
    "        networks (list): Current population of networks\n",
    "        dataset (str): Dataset to use for training/evaluating\n",
    "    \"\"\"\n",
    "    pbar = tqdm(total=len(networks))\n",
    "    for network in networks:\n",
    "        network.train()\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "def get_average_accuracy(networks):\n",
    "    \"\"\"Get the average accuracy for a group of networks.\n",
    "\n",
    "    Args:\n",
    "        networks (list): List of networks\n",
    "\n",
    "    Returns:\n",
    "        float: The average accuracy of a population of networks.\n",
    "\n",
    "    \"\"\"\n",
    "    total_accuracy = 0\n",
    "    for network in networks:\n",
    "        total_accuracy += network.accuracy\n",
    "\n",
    "    return total_accuracy / len(networks)\n",
    "\n",
    "def generate(generations, population, nn_param_choices):\n",
    "    \"\"\"Generate a network with the genetic algorithm.\n",
    "\n",
    "    Args:\n",
    "        generations (int): Number of times to evole the population\n",
    "        population (int): Number of networks in each generation\n",
    "        nn_param_choices (dict): Parameter choices for networks\n",
    "        dataset (str): Dataset to use for training/evaluating\n",
    "\n",
    "    \"\"\"\n",
    "    optimizer = Optimizer(nn_param_choices)\n",
    "    networks = optimizer.create_population(population)\n",
    "\n",
    "    # Evolve the generation.\n",
    "    for i in range(generations):\n",
    "        logging.info(\"***Doing generation %d of %d***\" %\n",
    "                     (i + 1, generations))\n",
    "\n",
    "        # Train and get accuracy for networks.\n",
    "        train_networks(networks)\n",
    "\n",
    "        # Get the average accuracy for this generation.\n",
    "        average_accuracy = get_average_accuracy(networks)\n",
    "\n",
    "        # Print out the average accuracy each generation.\n",
    "        logging.info(\"Generation average: %.10f%%\" % (1/average_accuracy))\n",
    "        logging.info('-'*80)\n",
    "\n",
    "        # Evolve, except on the last iteration.\n",
    "        if (i != generations - 1):\n",
    "            # Do the evolution.\n",
    "            networks = optimizer.evolve(networks)\n",
    "\n",
    "    # Sort our final population.\n",
    "    networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n",
    "\n",
    "    # Print out the top 5 networks.\n",
    "    print_networks(networks[:5])\n",
    "    return(networks[:3])\n",
    "\n",
    "def print_networks(networks):\n",
    "    \"\"\"Print a list of networks.\n",
    "\n",
    "    Args:\n",
    "        networks (list): The population of networks\n",
    "\n",
    "    \"\"\"\n",
    "    logging.info('-'*80)\n",
    "    for network in networks:\n",
    "        network.print_network()\n",
    "\n",
    "def main(classes, size, time_series):\n",
    "    global nb_classes\n",
    "    global test_size\n",
    "    global serie\n",
    "    nb_classes = classes\n",
    "    test_size = size\n",
    "    serie = time_series\n",
    "    generations = 5  # Number of times to evole the population.\n",
    "    population = 10  # Number of networks in each generation.\n",
    "\n",
    "    nn_param_choices = {\n",
    "        'nb_neurons': [4,6,8,12,24],\n",
    "        'i_neurons': [4,6,8,12],\n",
    "        'nb_layers': [1, 2, 3],\n",
    "        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n",
    "        'optimizer': ['adam', 'sgd'],\n",
    "    }\n",
    "\n",
    "    logging.info(\"***Evolving %d generations with population %d***\" %\n",
    "                 (generations, population))\n",
    "\n",
    "    networks = generate(generations, population, nn_param_choices)\n",
    "    return networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.20775683e-01],\n",
       "       [9.54690565e-01],\n",
       "       [5.70583047e-01],\n",
       "       [1.21599810e-01],\n",
       "       [2.05339715e-02],\n",
       "       [3.60304997e-01],\n",
       "       [8.28528973e-01],\n",
       "       [9.94722935e-01],\n",
       "       [7.06088921e-01],\n",
       "       [2.27995712e-01],\n",
       "       [0.00000000e+00],\n",
       "       [2.31719991e-01],\n",
       "       [7.10113394e-01],\n",
       "       [9.95347520e-01],\n",
       "       [8.25179430e-01],\n",
       "       [3.56060880e-01],\n",
       "       [1.92973023e-02],\n",
       "       [1.24507577e-01],\n",
       "       [5.74961862e-01],\n",
       "       [9.56514566e-01],\n",
       "       [9.18367892e-01],\n",
       "       [4.95593716e-01],\n",
       "       [7.68886662e-02],\n",
       "       [4.72082339e-02],\n",
       "       [4.33840472e-01],\n",
       "       [8.81317484e-01],\n",
       "       [9.78230968e-01],\n",
       "       [6.35479115e-01],\n",
       "       [1.68186397e-01],\n",
       "       [5.97958410e-03],\n",
       "       [2.97990872e-01],\n",
       "       [7.75746430e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.64573885e-01],\n",
       "       [2.85917769e-01],\n",
       "       [4.10587765e-03],\n",
       "       [1.78234764e-01],\n",
       "       [6.48211133e-01],\n",
       "       [9.81940879e-01],\n",
       "       [8.72594411e-01],\n",
       "       [4.20704369e-01],\n",
       "       [4.17363730e-02],\n",
       "       [8.41118507e-02],\n",
       "       [5.08870984e-01],\n",
       "       [9.25492184e-01],\n",
       "       [9.50935841e-01],\n",
       "       [5.61809175e-01],\n",
       "       [1.15873447e-01],\n",
       "       [2.31199090e-02],\n",
       "       [3.68825737e-01],\n",
       "       [8.35150586e-01],\n",
       "       [9.93357541e-01],\n",
       "       [6.97991857e-01],\n",
       "       [2.20611381e-01],\n",
       "       [1.17522355e-04],\n",
       "       [2.39231317e-01],\n",
       "       [7.18112644e-01],\n",
       "       [9.96480222e-01],\n",
       "       [8.18404181e-01],\n",
       "       [3.47606814e-01],\n",
       "       [1.69370476e-02],\n",
       "       [1.30411141e-01],\n",
       "       [5.83701535e-01],\n",
       "       [9.60055133e-01],\n",
       "       [9.13454172e-01],\n",
       "       [4.86743360e-01],\n",
       "       [7.22386511e-02],\n",
       "       [5.10337619e-02],\n",
       "       [4.42624370e-01],\n",
       "       [8.86983877e-01],\n",
       "       [9.75570200e-01],\n",
       "       [6.26937484e-01],\n",
       "       [1.61617039e-01],\n",
       "       [7.42233655e-03],\n",
       "       [3.06119275e-01],\n",
       "       [7.83087267e-01],\n",
       "       [9.99804140e-01],\n",
       "       [7.57021400e-01],\n",
       "       [2.77952379e-01],\n",
       "       [3.05092569e-03],\n",
       "       [1.85060168e-01],\n",
       "       [6.56641648e-01],\n",
       "       [9.84225528e-01],\n",
       "       [8.66632699e-01],\n",
       "       [4.11977466e-01],\n",
       "       [3.82677536e-02],\n",
       "       [8.90905475e-02],\n",
       "       [5.17719606e-01],\n",
       "       [9.30075349e-01],\n",
       "       [9.47039808e-01],\n",
       "       [5.53015938e-01],\n",
       "       [1.10267468e-01],\n",
       "       [2.58552987e-02],\n",
       "       [3.77387590e-01],\n",
       "       [8.41667174e-01],\n",
       "       [9.91837543e-01],\n",
       "       [6.89832752e-01],\n",
       "       [2.13314613e-01],\n",
       "       [3.91705380e-04],\n",
       "       [2.46824369e-01],\n",
       "       [7.26043549e-01],\n",
       "       [9.97457341e-01],\n",
       "       [8.11529157e-01],\n",
       "       [3.39200511e-01],\n",
       "       [1.47281827e-02],\n",
       "       [1.36430534e-01],\n",
       "       [5.92414984e-01],\n",
       "       [9.63451533e-01],\n",
       "       [9.08410888e-01],\n",
       "       [4.77897165e-01],\n",
       "       [6.77226952e-02],\n",
       "       [5.49999943e-02],\n",
       "       [4.51426255e-01],\n",
       "       [8.92529002e-01],\n",
       "       [9.72760403e-01],\n",
       "       [6.18356079e-01],\n",
       "       [1.55153730e-01],\n",
       "       [9.01946045e-03],\n",
       "       [3.14308443e-01],\n",
       "       [7.90339396e-01],\n",
       "       [9.99451655e-01],\n",
       "       [7.49388375e-01],\n",
       "       [2.70056582e-01],\n",
       "       [2.15171526e-03],\n",
       "       [1.91984275e-01],\n",
       "       [6.65023080e-01],\n",
       "       [9.86358436e-01],\n",
       "       [8.60556097e-01],\n",
       "       [4.03278154e-01],\n",
       "       [3.49438393e-02],\n",
       "       [9.41980223e-02],\n",
       "       [5.26562681e-01],\n",
       "       [9.34523742e-01],\n",
       "       [9.43003687e-01],\n",
       "       [5.44206094e-01],\n",
       "       [1.04783631e-01],\n",
       "       [2.87392833e-02],\n",
       "       [3.85987874e-01],\n",
       "       [8.48076696e-01],\n",
       "       [9.90163418e-01],\n",
       "       [6.81614162e-01],\n",
       "       [2.06107692e-01],\n",
       "       [8.22463173e-04],\n",
       "       [2.54496768e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TimeSeriesNN3():\n",
    "    def __init__(self,STEPS_AHEAD ,NUMBER_TESTING , SERIE, WINDOW):\n",
    "        self.STEPS_AHEAD = STEPS_AHEAD\n",
    "        self.WINDOW = WINDOW\n",
    "        self.NUMBER_TESTING = NUMBER_TESTING\n",
    "        self.SERIE = SERIE\n",
    "        self.SIZE = SERIE.shape[0]\n",
    "        self.NUMBER_TRAINING = self.SIZE - self.NUMBER_TESTING\n",
    "    \n",
    "    def divide_testing (self):\n",
    "        return (self.SERIE[:self.NUMBER_TRAINING],self.SERIE[self.NUMBER_TRAINING:])\n",
    "    \n",
    "    def divide_validation (self,serie):\n",
    "        experimentx = np.zeros((len(serie) - self.WINDOW -self.STEPS_AHEAD + 1, self.WINDOW))\n",
    "        experimenty = np.zeros((len(serie) - self.WINDOW -self.STEPS_AHEAD + 1,1))\n",
    "        cnt =  0\n",
    "        cnt2 = 0\n",
    "        #serie = serie.reset_index(drop = True)\n",
    "        for i in range (experimentx.shape[0]):\n",
    "            cnt += cnt2\n",
    "            for j in range (self.WINDOW):\n",
    "                experimentx[i][j] = serie[cnt]\n",
    "                cnt += 1   \n",
    "            experimenty[i] = serie[cnt + self.STEPS_AHEAD - 1]\n",
    "            cnt = 0\n",
    "            cnt2 += 1           \n",
    "        return (experimentx, experimenty)\n",
    "    \n",
    "    def batch (self):\n",
    "        training,testing = self.divide_testing()\n",
    "        tex,tey = self.divide_validation(testing)\n",
    "        tx,ty = self.divide_validation(training)        \n",
    "        return (tx,ty) , (tex,tey)\n",
    "training_data = pd.read_excel(\"NN3_FINAL_DATASET_WITH_TEST_DATA.xlsx\",sheet_name=\"Hoja 1\")\n",
    "training_data\n",
    "Serie_1 = training_data.iloc[:, 11:12].values\n",
    "Serie_1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "Serie_1 = scaler.fit_transform(Serie_1)  \n",
    "Serie_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hug0er\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\hug0er\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\hug0er\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[0.11695332825183868, 0.11695332825183868]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:02<00:22,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006443424616008997, 0.006443424616008997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:05<00:21,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0019890929106622934, 0.0019890929106622934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:07<00:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0030030265916138887, 0.0030030265916138887]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:09<00:14,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0009213085868395865, 0.0009213085868395865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:25<00:32,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005343177821487188, 0.005343177821487188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:30<00:24,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0030264134984463453, 0.0030264134984463453]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:56<00:35, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008725970983505249, 0.008725970983505249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:05<00:22, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004853127058595419, 0.004853127058595419]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [01:11<00:09,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006043697707355022, 0.006043697707355022]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:23<00:00, 10.36s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0008862777031026781, 0.0008862777031026781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:17<02:40, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00028850685339421034, 0.00028850685339421034]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:21<01:47, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.009011122398078442, 0.009011122398078442]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:25<01:14, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036492496728897095, 0.0036492496728897095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:50<01:29, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07760891318321228, 0.07760891318321228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:51<00:55, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002219595480710268, 0.002219595480710268]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:54<00:33,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15169161558151245, 0.15169161558151245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:56<00:19,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001427962793968618, 0.001427962793968618]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:15<00:20, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00015752646140754223, 0.00015752646140754223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [01:18<00:07,  7.97s/it]"
     ]
    }
   ],
   "source": [
    "a = main (1,14,Serie_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma = 0\n",
    "for i in a:\n",
    "    suma = suma + i.accuracy\n",
    "suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
